{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chest X-Ray Images (Pneumonia).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17RRh3l2G04hbdb5zyCDX3v-IHM5ql04p",
      "authorship_tag": "ABX9TyMRistNcXxy2Bx97wgSlJCp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebmes/ML-and-DL-projects/blob/main/Chest_X_Ray_Images_(Pneumonia).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQKMfEtpfkSZ",
        "outputId": "7c6b10c2-161d-44ef-8036-869c08d73348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoXscnHufnxR",
        "outputId": "33d53bc7-673a-4990-d3eb-33f986ba442a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download paultimothymooney/chest-xray-pneumonia --unzip --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xxIy-SUf5IJ",
        "outputId": "0d6c06b8-c66f-46fd-f7c9-30b0e49c5936"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [00:48<00:00, 70.0MB/s]\n",
            "100% 2.29G/2.29G [00:48<00:00, 50.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "jpjgxk7kjPgy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = os.path.join('/content', 'chest_xray', 'chest_xray')\n",
        "train_path = os.path.join(data_path, 'train')\n",
        "validation_path = os.path.join(data_path, 'val')\n",
        "test_path = os.path.join(data_path, 'test')"
      ],
      "metadata": {
        "id": "5ySewM1-gKYA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "train_augs = T.Compose([T.RandomHorizontalFlip(p=0.5), \n",
        "                        T.RandomRotation(degrees=(-20, +20)), \n",
        "                        T.Resize((64, 64)),\n",
        "                        T.ToTensor()])\n",
        "\n",
        "valid_augs = T.Compose([T.Resize((64, 64)), T.ToTensor()])"
      ],
      "metadata": {
        "id": "7ZKtTjndmHIw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = ImageFolder(train_path, transform=train_augs)\n",
        "validset = ImageFolder(validation_path, transform=valid_augs)\n",
        "print(f\"Total no. of examples in trainset : {len(trainset)}\")\n",
        "print(f\"Total no. of examples in validset : {len(validset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWCbaZ6umPdZ",
        "outputId": "240245a7-7e92-435b-ef9e-1a8c9a949ca4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of examples in trainset : 5216\n",
            "Total no. of examples in validset : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKNyuc7zmYjn",
        "outputId": "d31fa574-a497-44e7-93d0-3ef1506c390d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can view some images and their labels\n",
        "import matplotlib.pyplot as plt\n",
        "idx = np.random.randint(low=0, high=len(trainset)-1)\n",
        "print('chosen index: ', idx)\n",
        "image, label = trainset[idx] # the image has format of h, w, c -> so it have to be reshaped\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.title(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "nXLvRCtfmjMx",
        "outputId": "3d0735d9-1cab-432d-99c8-d150c0886af6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chosen index:  4213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '1')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "batch_size = 8\n",
        "epochs = 3\n",
        "\n",
        "#device\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('GPU available')\n",
        "else:\n",
        "  print('training is done on CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGbt0ZZxmzQZ",
        "outputId": "27545f07-a468-495f-e2d7-50b57d2c2a4b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's read the dataset using pytorch's dataloader\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, )\n",
        "validloader = DataLoader(validset, batch_size=batch_size)\n",
        "print('total batches in trainloader: ', len(trainloader), 'and validloader: ', len(validloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsyOnRfmmoxg",
        "outputId": "8b5966f0-c9ae-4a33-c6df-1e8338aeeaf6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total batches in trainloader:  652 and validloader:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57NdZQVtnJpp",
        "outputId": "854c9ec1-45ab-4408-d306-b44bf8a34def"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ],
      "metadata": {
        "id": "iS_5VZwQoyk7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, optimizer, current_epoch):\n",
        "\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TRAIN]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # logits, loss = model(images, labels)\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def eval_model(model, dataloader, current_epoch):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[VALID]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # logits, loss = model(images, labels)\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)"
      ],
      "metadata": {
        "id": "TJw7XXO2o7DA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's train the model\n",
        "from torch import optim\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5, weight_decay=1e-2, nesterov=True)"
      ],
      "metadata": {
        "id": "NDokfk9jpA9_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in trainset:\n",
        "  break\n",
        "print('images batch shape: ', images.shape)\n",
        "print('labels batch shape', labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaMumPnmtbHL",
        "outputId": "e413fa79-d15b-4e56-ac30-659bbd36caef"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images batch shape:  torch.Size([3, 64, 64])\n",
            "labels batch shape 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = np.Inf\n",
        "for i in range(epochs):\n",
        "  train_loss, train_acc = train_model(model, trainloader, optimizer, i)\n",
        "  valid_loss, valid_acc = eval_model(model, validloader, i)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), 'best-weights.pt')\n",
        "    print('SAVED BEST WEIGHTS')\n",
        "    best_valid_loss = valid_loss\n",
        "print()\n",
        "print()\n",
        "print('accuracy on the training set: ', float(train_acc))\n",
        "print('accuracy on the validation set: ', float(valid_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6j5-3pTpEzg",
        "outputId": "0f4ae155-888c-4b9e-f67d-8b251489f4b4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]1/3: 100%|██████████| 652/652 [02:30<00:00,  4.32it/s, loss=0.428, acc=0.897]\n",
            "EPOCH[VALID]1/3: 100%|██████████| 2/2 [00:00<00:00,  8.05it/s, loss=0.339, acc=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]2/3: 100%|██████████| 652/652 [02:29<00:00,  4.35it/s, loss=0.136, acc=0.947]\n",
            "EPOCH[VALID]2/3: 100%|██████████| 2/2 [00:00<00:00,  8.00it/s, loss=0.628, acc=0.75]\n",
            "EPOCH[TRAIN]3/3: 100%|██████████| 652/652 [02:29<00:00,  4.37it/s, loss=0.115, acc=0.956]\n",
            "EPOCH[VALID]3/3: 100%|██████████| 2/2 [00:00<00:00,  8.54it/s, loss=0.555, acc=0.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "accuracy on the training set:  0.956480085849762\n",
            "accuracy on the validation set:  0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}